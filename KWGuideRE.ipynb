{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os, glob, numpy as np #이미지 프로세싱\n",
    "from sklearn.model_selection import train_test_split #train set과 test set으로 분류 \n",
    "\n",
    "# 데이터셋 저장한 디렉토리\n",
    "base_dir = './KWGuideImg/dataset/train'\n",
    "categories=os.listdir(base_dir) #[\"기념\",\"화도\",\"옥의\",\"비마\",\"새빛\",\"참빛\",\"한울\",\"연구\"]\n",
    "nb_classes=len(categories) #class 개수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#ImageDataGenerator 클래스 사용하여 이미지 데이터 증식\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40, #이미지 회전 범위\n",
    "    width_shift_range=0.2, #그림 수평 or 수직으로 랜덤하게 평행이동시키는 범위\n",
    "    height_shift_range=0.2,\n",
    "    rescale=1./255, #1/255로 스케일링하여 0~1범위로 변환하여 효과적으로 학습\n",
    "    shear_range=0.2, #임의 전단 변환\n",
    "    zoom_range=0.2, #임의 확대/축소 범위\n",
    "    horizontal_flip=False, #이미지를 50%확률로 수평으로 뒤집음(뒤집으면 자연스럽지 않으므로, False) \n",
    "    fill_mode='nearest') #이미지를 회전, 이동하거나 축소할 때 생기는 공간 채움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련용 80주념기념관 사진 디렉터리\n",
    "train_ginyeom_dir = './KWGuideImg/dataset/train/ginyeom'\n",
    "\n",
    "# 훈련용 화도관 사진 디렉터리\n",
    "train_hwado_dir = './KWGuideImg/dataset/train/hwado'\n",
    "\n",
    "# 훈련용 새빛관 사진 디렉터리\n",
    "train_saebit_dir = './KWGuideImg/dataset/train/saebit'\n",
    "\n",
    "# 훈련용 비마관 사진 디렉터리\n",
    "train_bima_dir = './KWGuideImg/dataset/train/bima'\n",
    "\n",
    "# 훈련용 옥의관 사진 디렉터리\n",
    "train_oakui_dir = './KWGuideImg/dataset/train/oakeui'\n",
    "\n",
    "# 훈련용 한천재 사진 디렉터리\n",
    "train_hancheon_dir = './KWGuideImg/dataset/train/hanchoen'\n",
    "\n",
    "# 훈련용 복지관 사진 디렉터리\n",
    "train_bokji_dir = './KWGuideImg/dataset/train/bok'\n",
    "\n",
    "# 훈련용 연구관 사진 디렉터리\n",
    "train_yeonku_dir = './KWGuideImg/dataset/train/yeon'\n",
    "\n",
    "# 훈련용 참빛관 사진 디렉터리\n",
    "train_chambit_dir = './KWGuideImg/dataset/train/chambit'\n",
    "\n",
    "# 훈련용 한울관 사진 디렉터리\n",
    "train_hanoul_dir = './KWGuideImg/dataset/train/hanoul'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 전처리 유틸리티 모듈\n",
    "from keras.preprocessing import image\n",
    "\n",
    "fnames1 = sorted([os.path.join(train_ginyeom_dir, fname) for fname in os.listdir(train_ginyeom_dir)])\n",
    "fnames2 = sorted([os.path.join(train_hwado_dir, fname) for fname in os.listdir(train_hwado_dir)])\n",
    "fnames3 = sorted([os.path.join(train_saebit_dir, fname) for fname in os.listdir(train_saebit_dir)])\n",
    "fnames4 = sorted([os.path.join(train_bima_dir, fname) for fname in os.listdir(train_bima_dir)])\n",
    "fnames5 = sorted([os.path.join(train_oakui_dir, fname) for fname in os.listdir(train_oakui_dir)])\n",
    "fnames6 = sorted([os.path.join(train_chambit_dir, fname) for fname in os.listdir(train_chambit_dir)])\n",
    "fnames7 = sorted([os.path.join(train_hanoul_dir, fname) for fname in os.listdir(train_hanoul_dir)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#이미지 데이터 증식 (한번만 수행)\n",
    "\n",
    "for img_path in fnames1:\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(150, 150)) # 이미지 읽고 크기 변경\n",
    "\n",
    "    x = image.img_to_array(img) # (150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    x = x.reshape((1,) + x.shape) # (1, 150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    # flow() 메서드로 랜덤하게 변환된 이미지를 배치 단위로 생성하여 폴더에 저장\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,\n",
    "                             save_to_dir='./KWGuideImg/dataset/train/gi',save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > 10:\n",
    "            break #이미지 10장 생성\n",
    "\n",
    "for img_path in fnames2:\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(150, 150)) # 이미지 읽고 크기 변경\n",
    "\n",
    "    x = image.img_to_array(img) # (150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    x = x.reshape((1,) + x.shape) # (1, 150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    # flow() 메서드로 랜덤하게 변환된 이미지를 배치 단위로 생성하여 폴더에 저장\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,\n",
    "                             save_to_dir='./KWGuideImg/dataset/train/hwan',save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > 10:\n",
    "            break #이미지 10장 생성\n",
    "for img_path in fnames3:\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(150, 150)) # 이미지 읽고 크기 변경\n",
    "\n",
    "    x = image.img_to_array(img) # (150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    x = x.reshape((1,) + x.shape) # (1, 150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    # flow() 메서드로 랜덤하게 변환된 이미지를 배치 단위로 생성하여 폴더에 저장\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,\n",
    "                             save_to_dir='./KWGuideImg/dataset/train/se',save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > 10:\n",
    "            break #이미지 10장 생성\n",
    "for img_path in fnames4:\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(150, 150)) # 이미지 읽고 크기 변경\n",
    "\n",
    "    x = image.img_to_array(img) # (150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    x = x.reshape((1,) + x.shape) # (1, 150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    # flow() 메서드로 랜덤하게 변환된 이미지를 배치 단위로 생성하여 폴더에 저장\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,\n",
    "                             save_to_dir='./KWGuideImg/dataset/train/bi',save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > 10:\n",
    "            break #이미지 10장 생성\n",
    "for img_path in fnames5:\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(150, 150)) # 이미지 읽고 크기 변경\n",
    "\n",
    "    x = image.img_to_array(img) # (150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    x = x.reshape((1,) + x.shape) # (1, 150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    # flow() 메서드로 랜덤하게 변환된 이미지를 배치 단위로 생성하여 폴더에 저장\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,\n",
    "                             save_to_dir='./KWGuideImg/dataset/train/oak',save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > 10:\n",
    "            break #이미지 10장 생성\n",
    "for img_path in fnames6:\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(150, 150)) # 이미지 읽고 크기 변경\n",
    "\n",
    "    x = image.img_to_array(img) # (150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    x = x.reshape((1,) + x.shape) # (1, 150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    # flow() 메서드로 랜덤하게 변환된 이미지를 배치 단위로 생성하여 폴더에 저장\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,\n",
    "                             save_to_dir='./KWGuideImg/dataset/train/cham',save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > 10:\n",
    "            break #이미지 10장 생성\n",
    "\n",
    "for img_path in fnames7:\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(150, 150)) # 이미지 읽고 크기 변경\n",
    "\n",
    "    x = image.img_to_array(img) # (150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    x = x.reshape((1,) + x.shape) # (1, 150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    # flow() 메서드로 랜덤하게 변환된 이미지를 배치 단위로 생성하여 폴더에 저장\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,\n",
    "                             save_to_dir='./KWGuideImg/dataset/train/hanoul',save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > 10:\n",
    "            break #이미지 10장 생성            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bima  File Size :  424\n",
      "bima  :  ./KWGuideImg/dataset/train/bima\\image_024.jpg\n",
      "bok  File Size :  7\n",
      "bok  :  ./KWGuideImg/dataset/train/bok\\image_014.jpg\n",
      "chambit  File Size :  837\n",
      "chambit  :  ./KWGuideImg/dataset/train/chambit\\image_029.jpg\n",
      "chambit  :  ./KWGuideImg/dataset/train/chambit\\_0_8364.jpg\n",
      "ginyeom  File Size :  2341\n",
      "ginyeom  :  ./KWGuideImg/dataset/train/ginyeom\\image_001.jpg\n",
      "ginyeom  :  ./KWGuideImg/dataset/train/ginyeom\\_0_3764.jpg\n",
      "ginyeom  :  ./KWGuideImg/dataset/train/ginyeom\\_0_6489.jpg\n",
      "ginyeom  :  ./KWGuideImg/dataset/train/ginyeom\\_0_9112.jpg\n",
      "hanchoen  File Size :  1\n",
      "hanchoen  :  ./KWGuideImg/dataset/train/hanchoen\\image_035.jpg\n",
      "hanoul  File Size :  423\n",
      "hanoul  :  ./KWGuideImg/dataset/train/hanoul\\image_031.jpg\n",
      "hwado  File Size :  1222\n",
      "hwado  :  ./KWGuideImg/dataset/train/hwado\\image_011.jpg\n",
      "hwado  :  ./KWGuideImg/dataset/train/hwado\\_0_6216.jpg\n",
      "oakeui  File Size :  796\n",
      "oakeui  :  ./KWGuideImg/dataset/train/oakeui\\image_025.jpg\n",
      "oakeui  :  ./KWGuideImg/dataset/train/oakeui\\_0_884.jpg\n",
      "saebit  File Size :  836\n",
      "saebit  :  ./KWGuideImg/dataset/train/saebit\\image_030.jpg\n",
      "saebit  :  ./KWGuideImg/dataset/train/saebit\\_0_8410.jpg\n",
      "yeon  File Size :  3\n",
      "yeon  :  ./KWGuideImg/dataset/train/yeon\\image_032.jpg\n",
      "ok 6890\n"
     ]
    }
   ],
   "source": [
    "image_w = 64\n",
    "image_h = 64 #크기지정\n",
    "\n",
    "pixels = image_h * image_w * 3\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for idx, cat in enumerate(categories):  #각 건물마다\n",
    "    \n",
    "    label = [0 for i in range(nb_classes)] #건물 카테고리 개수\n",
    "    label[idx] = 1\n",
    "\n",
    "    image_ = base_dir + \"/\" + cat\n",
    "    files = glob.glob(image_+\"/*.jpg\")\n",
    "    print(cat, \" File Size : \", len(files))\n",
    "    for i, f in enumerate(files):\n",
    "        img = Image.open(f)\n",
    "        img = img.convert(\"RGB\") #RGB로 변환 \n",
    "        img = img.resize((image_w, image_h)) #크기 (64,64)로 변환\n",
    "        data = np.asarray(img) #numpy.ndarray()형식으로 변환\n",
    "\n",
    "        X.append(data) #train image\n",
    "        y.append(label) #train label \n",
    "\n",
    "        if i % 700 == 0:\n",
    "            print(cat, \" : \", f)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "#1 0 0 0 0 0 0 이면 기념관\n",
    "#0 1 0 0 0 0 0이면 화도관\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y) #트레인이미지와 테스트이미지 나눔\n",
    "xy = (X_train, X_test, y_train, y_test)\n",
    "np.save('dataset_numpy.npy', xy) #(\"C:/KWGuideImg/dataset/test\", xy) \n",
    "\n",
    "print(\"ok\", len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5167, 64, 64, 3)\n",
      "5167\n",
      "(5167, 10)\n"
     ]
    }
   ],
   "source": [
    "#numpy 데이터 불러옴\n",
    "import os, glob, numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend.tensorflow_backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "config =  tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "\n",
    "X_train, X_test, y_train, y_test = np.load('dataset_numpy.npy',allow_pickle=True)\n",
    "print(X_train.shape)\n",
    "print(X_train.shape[0])\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "categories=os.listdir(base_dir)\n",
    "nb_classes = len(categories)\n",
    "\n",
    "#train/ test분류\n",
    "X_train = X_train.astype(float) / 255\n",
    "X_test = X_test.astype(float) / 255\n",
    "print (\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "with K.tf_ops.device('/device:CPU:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:], activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3), padding=\"same\", activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes, activation='sigmoid'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model_dir = './model'\n",
    "    \n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "    model_path = model_dir + '/multi_img_classification.model'\n",
    "    checkpoint = ModelCheckpoint(filepath=model_path , monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=6)\n",
    "    \n",
    "    print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               4194560   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 4,216,522\n",
      "Trainable params: 4,216,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "5167/5167 [==============================] - 24s 5ms/step - loss: 1.7858 - accuracy: 0.3331\n",
      "Epoch 2/30\n",
      "5167/5167 [==============================] - 29s 6ms/step - loss: 1.3517 - accuracy: 0.3753\n",
      "Epoch 3/30\n",
      "5167/5167 [==============================] - 27s 5ms/step - loss: 0.9227 - accuracy: 0.6623\n",
      "Epoch 4/30\n",
      "5167/5167 [==============================] - 27s 5ms/step - loss: 0.5859 - accuracy: 0.8028\n",
      "Epoch 5/30\n",
      "5167/5167 [==============================] - 28s 5ms/step - loss: 0.3923 - accuracy: 0.8698\n",
      "Epoch 6/30\n",
      "5167/5167 [==============================] - 32s 6ms/step - loss: 0.2765 - accuracy: 0.9087\n",
      "Epoch 7/30\n",
      "5167/5167 [==============================] - 27s 5ms/step - loss: 0.2192 - accuracy: 0.9313\n",
      "Epoch 8/30\n",
      "5167/5167 [==============================] - 27s 5ms/step - loss: 0.1751 - accuracy: 0.9462\n",
      "Epoch 9/30\n",
      "5167/5167 [==============================] - 27s 5ms/step - loss: 0.1576 - accuracy: 0.9491\n",
      "Epoch 10/30\n",
      "5167/5167 [==============================] - 27s 5ms/step - loss: 0.1201 - accuracy: 0.9605\n",
      "Epoch 11/30\n",
      "5167/5167 [==============================] - 29s 6ms/step - loss: 0.1125 - accuracy: 0.9644 2s - loss:\n",
      "Epoch 12/30\n",
      "5167/5167 [==============================] - 27s 5ms/step - loss: 0.0961 - accuracy: 0.9704\n",
      "Epoch 13/30\n",
      "5167/5167 [==============================] - 27s 5ms/step - loss: 0.0748 - accuracy: 0.9774\n",
      "Epoch 14/30\n",
      "5167/5167 [==============================] - 27s 5ms/step - loss: 0.0957 - accuracy: 0.9706\n",
      "Epoch 15/30\n",
      "5167/5167 [==============================] - 30s 6ms/step - loss: 0.0785 - accuracy: 0.9746\n",
      "Epoch 16/30\n",
      "5167/5167 [==============================] - 28s 5ms/step - loss: 0.0655 - accuracy: 0.9808 0s - loss: 0.0661 - accuracy\n",
      "Epoch 17/30\n",
      "5167/5167 [==============================] - 27s 5ms/step - loss: 0.0642 - accuracy: 0.9806\n",
      "Epoch 18/30\n",
      "5167/5167 [==============================] - 27s 5ms/step - loss: 0.0813 - accuracy: 0.9741\n",
      "Epoch 19/30\n",
      "5167/5167 [==============================] - 27s 5ms/step - loss: 0.0581 - accuracy: 0.9832\n",
      "Epoch 20/30\n",
      "5167/5167 [==============================] - 27s 5ms/step - loss: 0.0488 - accuracy: 0.9859 2s - l\n",
      "Epoch 21/30\n",
      "5167/5167 [==============================] - 27s 5ms/step - loss: 0.0789 - accuracy: 0.9793\n",
      "Epoch 22/30\n",
      "5167/5167 [==============================] - 27s 5ms/step - loss: 0.0495 - accuracy: 0.9837 1s - loss: 0.0\n",
      "Epoch 23/30\n",
      "5167/5167 [==============================] - 27s 5ms/step - loss: 0.0439 - accuracy: 0.9876\n",
      "Epoch 24/30\n",
      "5167/5167 [==============================] - 29s 6ms/step - loss: 0.0565 - accuracy: 0.9826\n",
      "Epoch 25/30\n",
      "5167/5167 [==============================] - 29s 6ms/step - loss: 0.0438 - accuracy: 0.9866\n",
      "Epoch 26/30\n",
      "5167/5167 [==============================] - 28s 5ms/step - loss: 0.0471 - accuracy: 0.9857\n",
      "Epoch 27/30\n",
      "5167/5167 [==============================] - 28s 5ms/step - loss: 0.0410 - accuracy: 0.9859\n",
      "Epoch 28/30\n",
      "5167/5167 [==============================] - 29s 6ms/step - loss: 0.0638 - accuracy: 0.9805\n",
      "Epoch 29/30\n",
      "5167/5167 [==============================] - 27s 5ms/step - loss: 0.0377 - accuracy: 0.9888\n",
      "Epoch 30/30\n",
      "5167/5167 [==============================] - 27s 5ms/step - loss: 0.0433 - accuracy: 0.9857\n",
      "1723/1723 [==============================] - 2s 1ms/step\n",
      "정확도 : 0.9837\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=30)\n",
    "\n",
    "print(\"정확도 : %.4f\" % (model.evaluate(X_test, y_test)[1]))\n",
    "\n",
    "model.save('Building_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./KWGuideImg/dataset/test/test_img2.jpg\n",
      "saebit\n"
     ]
    }
   ],
   "source": [
    "msg='./KWGuideImg/dataset/test/test_img2.jpg'\n",
    "print(msg)\n",
    "img = Image.open(msg)\n",
    "img = img.convert(\"RGB\")\n",
    "image_w = 64\n",
    "image_h = 64 #크기지정\n",
    "img = img.resize((image_w, image_h)) #사이즈 재조정\n",
    "data = np.asarray(img)\n",
    "X=np.array(data)\n",
    "\n",
    "X = X.astype(\"float\") / 256\n",
    "X = X.reshape(-1, 64, 64,3)\n",
    "\n",
    "#훈련된 모델을 사용하여 이미지 예측\n",
    "model=load_model('Building_cnn.h5')\n",
    "predictions = model.predict(X)  #X이미지 레이블 예측\n",
    "predictions[0]\n",
    "result = np.argmax(predictions[0])    # 예측 값중 가장 높은 신뢰도를 가진 레이블\n",
    "base_dir = './KWGuideImg/dataset/train'\n",
    "categories=os.listdir(base_dir) #[\"기념\",\"화도\",\"옥의\",\"비마\",\"새빛\",\"참빛\",\"한울\",\"연구\"]\n",
    "cnn_result = str(categories[result])       # 수신된 메시지 앞에 「echo:」 라는 메시지를 붙힌다.\n",
    "print(cnn_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
