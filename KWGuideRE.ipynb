{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os, glob, numpy as np #이미지 프로세싱\n",
    "from sklearn.model_selection import train_test_split #train set과 test set으로 분류 \n",
    "\n",
    "# 데이터셋 저장한 디렉토리\n",
    "base_dir = './KWGuideImg/dataset/train'\n",
    "categories=os.listdir(base_dir) #[\"기념\",\"화도\",\"옥의\",\"비마\",\"새빛\",\"참빛\",\"한울\",\"연구\"]\n",
    "nb_classes=len(categories) #class 개수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#ImageDataGenerator 클래스 사용하여 이미지 데이터 증식\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40, #이미지 회전 범위\n",
    "    width_shift_range=0.2, #그림 수평 or 수직으로 랜덤하게 평행이동시키는 범위\n",
    "    height_shift_range=0.2,\n",
    "    rescale=1./255, #1/255로 스케일링하여 0~1범위로 변환하여 효과적으로 학습\n",
    "    shear_range=0.2, #임의 전단 변환\n",
    "    zoom_range=0.2, #임의 확대/축소 범위\n",
    "    horizontal_flip=False, #이미지를 50%확률로 수평으로 뒤집음(뒤집으면 자연스럽지 않으므로, False) \n",
    "    fill_mode='nearest') #이미지를 회전, 이동하거나 축소할 때 생기는 공간 채움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련용 80주념기념관 사진 디렉터리\n",
    "train_ginyeom_dir = './KWGuideImg/dataset/train/gi'\n",
    "\n",
    "# 훈련용 화도관 사진 디렉터리\n",
    "train_hwado_dir = './KWGuideImg/dataset/train/hwan'\n",
    "\n",
    "# 훈련용 새빛관 사진 디렉터리\n",
    "train_saebit_dir = './KWGuideImg/dataset/train/se'\n",
    "\n",
    "# 훈련용 비마관 사진 디렉터리\n",
    "train_bima_dir = './KWGuideImg/dataset/train/bi'\n",
    "\n",
    "# 훈련용 옥의관 사진 디렉터리\n",
    "train_oakui_dir = './KWGuideImg/dataset/train/oak'\n",
    "\n",
    "# 훈련용 한천재 사진 디렉터리\n",
    "train_hancheon_dir = './KWGuideImg/dataset/train/hanchoen'\n",
    "\n",
    "# 훈련용 복지관 사진 디렉터리\n",
    "train_bokji_dir = './KWGuideImg/dataset/train/bok'\n",
    "\n",
    "# 훈련용 연구관 사진 디렉터리\n",
    "train_yeonku_dir = './KWGuideImg/dataset/train/yeon'\n",
    "\n",
    "# 훈련용 참빛관 사진 디렉터리\n",
    "train_chambit_dir = './KWGuideImg/dataset/train/cham'\n",
    "\n",
    "# 훈련용 한울관 사진 디렉터리\n",
    "train_hanoul_dir = './KWGuideImg/dataset/train/hanoul'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 전처리 유틸리티 모듈\n",
    "from keras.preprocessing import image\n",
    "\n",
    "fnames1 = sorted([os.path.join(train_ginyeom_dir, fname) for fname in os.listdir(train_ginyeom_dir)])\n",
    "fnames2 = sorted([os.path.join(train_hwado_dir, fname) for fname in os.listdir(train_hwado_dir)])\n",
    "fnames3 = sorted([os.path.join(train_saebit_dir, fname) for fname in os.listdir(train_saebit_dir)])\n",
    "fnames4 = sorted([os.path.join(train_bima_dir, fname) for fname in os.listdir(train_bima_dir)])\n",
    "fnames5 = sorted([os.path.join(train_oakui_dir, fname) for fname in os.listdir(train_oakui_dir)])\n",
    "fnames6 = sorted([os.path.join(train_chambit_dir, fname) for fname in os.listdir(train_chambit_dir)])\n",
    "fnames7 = sorted([os.path.join(train_hanoul_dir, fname) for fname in os.listdir(train_hanoul_dir)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#이미지 데이터 증식 (한번만 수행)\n",
    "\n",
    "for img_path in fnames1:\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(150, 150)) # 이미지 읽고 크기 변경\n",
    "\n",
    "    x = image.img_to_array(img) # (150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    x = x.reshape((1,) + x.shape) # (1, 150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    # flow() 메서드로 랜덤하게 변환된 이미지를 배치 단위로 생성하여 폴더에 저장\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,\n",
    "                             save_to_dir='./KWGuideImg/dataset/train/gi',save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > 10:\n",
    "            break #이미지 10장 생성\n",
    "\n",
    "for img_path in fnames2:\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(150, 150)) # 이미지 읽고 크기 변경\n",
    "\n",
    "    x = image.img_to_array(img) # (150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    x = x.reshape((1,) + x.shape) # (1, 150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    # flow() 메서드로 랜덤하게 변환된 이미지를 배치 단위로 생성하여 폴더에 저장\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,\n",
    "                             save_to_dir='./KWGuideImg/dataset/train/hwan',save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > 10:\n",
    "            break #이미지 10장 생성\n",
    "for img_path in fnames3:\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(150, 150)) # 이미지 읽고 크기 변경\n",
    "\n",
    "    x = image.img_to_array(img) # (150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    x = x.reshape((1,) + x.shape) # (1, 150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    # flow() 메서드로 랜덤하게 변환된 이미지를 배치 단위로 생성하여 폴더에 저장\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,\n",
    "                             save_to_dir='./KWGuideImg/dataset/train/se',save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > 10:\n",
    "            break #이미지 10장 생성\n",
    "for img_path in fnames4:\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(150, 150)) # 이미지 읽고 크기 변경\n",
    "\n",
    "    x = image.img_to_array(img) # (150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    x = x.reshape((1,) + x.shape) # (1, 150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    # flow() 메서드로 랜덤하게 변환된 이미지를 배치 단위로 생성하여 폴더에 저장\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,\n",
    "                             save_to_dir='./KWGuideImg/dataset/train/bi',save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > 10:\n",
    "            break #이미지 10장 생성\n",
    "for img_path in fnames5:\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(150, 150)) # 이미지 읽고 크기 변경\n",
    "\n",
    "    x = image.img_to_array(img) # (150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    x = x.reshape((1,) + x.shape) # (1, 150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    # flow() 메서드로 랜덤하게 변환된 이미지를 배치 단위로 생성하여 폴더에 저장\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,\n",
    "                             save_to_dir='./KWGuideImg/dataset/train/oak',save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > 10:\n",
    "            break #이미지 10장 생성\n",
    "for img_path in fnames6:\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(150, 150)) # 이미지 읽고 크기 변경\n",
    "\n",
    "    x = image.img_to_array(img) # (150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    x = x.reshape((1,) + x.shape) # (1, 150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    # flow() 메서드로 랜덤하게 변환된 이미지를 배치 단위로 생성하여 폴더에 저장\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,\n",
    "                             save_to_dir='./KWGuideImg/dataset/train/cham',save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > 10:\n",
    "            break #이미지 10장 생성\n",
    "\n",
    "for img_path in fnames7:\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(150, 150)) # 이미지 읽고 크기 변경\n",
    "\n",
    "    x = image.img_to_array(img) # (150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    x = x.reshape((1,) + x.shape) # (1, 150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    # flow() 메서드로 랜덤하게 변환된 이미지를 배치 단위로 생성하여 폴더에 저장\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,\n",
    "                             save_to_dir='./KWGuideImg/dataset/train/hanoul',save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > 10:\n",
    "            break #이미지 10장 생성            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bi  File Size :  424\n",
      "bi  :  ./KWGuideImg/dataset/train/bi\\image_024.jpg\n",
      "bok  File Size :  7\n",
      "bok  :  ./KWGuideImg/dataset/train/bok\\image_014.jpg\n",
      "cham  File Size :  837\n",
      "cham  :  ./KWGuideImg/dataset/train/cham\\image_029.jpg\n",
      "cham  :  ./KWGuideImg/dataset/train/cham\\_0_8364.jpg\n",
      "gi  File Size :  2341\n",
      "gi  :  ./KWGuideImg/dataset/train/gi\\image_001.jpg\n",
      "gi  :  ./KWGuideImg/dataset/train/gi\\_0_3764.jpg\n",
      "gi  :  ./KWGuideImg/dataset/train/gi\\_0_6489.jpg\n",
      "gi  :  ./KWGuideImg/dataset/train/gi\\_0_9112.jpg\n",
      "hanchoen  File Size :  1\n",
      "hanchoen  :  ./KWGuideImg/dataset/train/hanchoen\\image_035.jpg\n",
      "hanoul  File Size :  423\n",
      "hanoul  :  ./KWGuideImg/dataset/train/hanoul\\image_031.jpg\n",
      "hwan  File Size :  1222\n",
      "hwan  :  ./KWGuideImg/dataset/train/hwan\\image_011.jpg\n",
      "hwan  :  ./KWGuideImg/dataset/train/hwan\\_0_6216.jpg\n",
      "oak  File Size :  796\n",
      "oak  :  ./KWGuideImg/dataset/train/oak\\image_025.jpg\n",
      "oak  :  ./KWGuideImg/dataset/train/oak\\_0_884.jpg\n",
      "se  File Size :  836\n",
      "se  :  ./KWGuideImg/dataset/train/se\\image_030.jpg\n",
      "se  :  ./KWGuideImg/dataset/train/se\\_0_8410.jpg\n",
      "yeon  File Size :  3\n",
      "yeon  :  ./KWGuideImg/dataset/train/yeon\\image_032.jpg\n",
      "ok 6890\n"
     ]
    }
   ],
   "source": [
    "image_w = 64\n",
    "image_h = 64 #크기지정\n",
    "\n",
    "pixels = image_h * image_w * 3\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for idx, cat in enumerate(categories):  #각 건물마다\n",
    "    \n",
    "    label = [0 for i in range(nb_classes)] #건물 카테고리 개수\n",
    "    label[idx] = 1\n",
    "\n",
    "    image_ = base_dir + \"/\" + cat\n",
    "    files = glob.glob(image_+\"/*.jpg\")\n",
    "    print(cat, \" File Size : \", len(files))\n",
    "    for i, f in enumerate(files):\n",
    "        img = Image.open(f)\n",
    "        img = img.convert(\"RGB\") #RGB로 변환 \n",
    "        img = img.resize((image_w, image_h)) #크기 (64,64)로 변환\n",
    "        data = np.asarray(img) #numpy.ndarray()형식으로 변환\n",
    "\n",
    "        X.append(data) #train image\n",
    "        y.append(label) #train label \n",
    "\n",
    "        if i % 700 == 0:\n",
    "            print(cat, \" : \", f)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "#1 0 0 0 0 0 0 이면 기념관\n",
    "#0 1 0 0 0 0 0이면 화도관\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y) #트레인이미지와 테스트이미지 나눔\n",
    "xy = (X_train, X_test, y_train, y_test)\n",
    "np.save('dataset_numpy.npy', xy) #(\"C:/KWGuideImg/dataset/test\", xy) \n",
    "\n",
    "print(\"ok\", len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5167, 64, 64, 3)\n",
      "5167\n",
      "(5167, 10)\n"
     ]
    }
   ],
   "source": [
    "#numpy 데이터 불러옴\n",
    "import os, glob, numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend.tensorflow_backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "config =  tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "\n",
    "X_train, X_test, y_train, y_test = np.load('dataset_numpy.npy',allow_pickle=True)\n",
    "print(X_train.shape)\n",
    "print(X_train.shape[0])\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "categories=os.listdir(base_dir)\n",
    "nb_classes = len(categories)\n",
    "\n",
    "#train/ test분류\n",
    "X_train = X_train.astype(float) / 255\n",
    "X_test = X_test.astype(float) / 255\n",
    "print (\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "with K.tf_ops.device('/device:CPU:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:], activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3), padding=\"same\", activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes, activation='sigmoid'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model_dir = './model'\n",
    "    \n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "    model_path = model_dir + '/multi_img_classification.model'\n",
    "    checkpoint = ModelCheckpoint(filepath=model_path , monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=6)\n",
    "    \n",
    "    print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               4194560   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 4,216,522\n",
      "Trainable params: 4,216,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "5167/5167 [==============================] - 24s 5ms/step - loss: 1.6926 - accuracy: 0.3406\n",
      "1723/1723 [==============================] - 2s 1ms/step\n",
      "정확도 : 0.5113\n"
     ]
    }
   ],
   "source": [
    "#validation 변경 -> validation_split=0.2\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=1)\n",
    "#, validation_data=(X_test, y_test), callbacks=[checkpoint, early_stopping]\n",
    "print(\"정확도 : %.4f\" % (model.evaluate(X_test, y_test)[1]))\n",
    "\n",
    "model.save('Building_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os, glob, numpy as np\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected by ('127.0.0.1', 57572)\n",
      "Received from ('127.0.0.1', 57572) C:\\github\\KW_GuideBook\\KWGuideImg\\dataset\\test\\test_img2.jpg\n",
      "hi\n",
      "except :  ('127.0.0.1', 57572)\n"
     ]
    }
   ],
   "source": [
    "import socket, threading;\n",
    "\n",
    "def binder(client_socket, addr): # binder함수는 서버에서 accept가 되면 생성되는 socket 인스턴스를 통해 client로 부터 데이터를 받으면 echo형태로 재송신하는 메소드\n",
    "    \n",
    "    print('Connected by', addr); # 커넥션이 되면 접속 주소가 나온다.\n",
    "    try:\n",
    "    # 접속 상태에서는 클라이언트로 부터 받을 데이터를 무한 대기한다.\n",
    "    # 만약 접속이 끊기게 된다면 except가 발생해서 접속이 끊기게 된다.\n",
    "        while True:\n",
    "            data = client_socket.recv(4)  # socket의 recv함수는 연결된 소켓으로부터 데이터를 받을 대기하는 함수\n",
    "        \n",
    "            length = int.from_bytes(data, \"big\")    # 최초 4바이트는 전송할 데이터의 크기이다. 그 크기는 big 엔디언으로 byte에서 int형식으로 변환한다.C#의 BitConverter는 big엔디언으로 처리된다.\n",
    "        \n",
    "            data = client_socket.recv(length) # 다시 데이터 수신\n",
    "            \n",
    "            msg = data.decode() # 수신된 데이터를 str형식으로 decode한다.\n",
    "            \n",
    "            print('Received from', addr, msg) # 수신된 메시지를 콘솔에 출력한다.\n",
    "            \n",
    "            img = Image.open(msg)\n",
    "            img = img.convert(\"RGB\")\n",
    "            img = img.resize((image_w, image_h)) #사이즈 재조정\n",
    "            data = np.asarray(img)\n",
    "            X=np.array(data)\n",
    "\n",
    "            X = X.astype(\"float\") / 256\n",
    "            X = X.reshape(-1, 64, 64,3)\n",
    "            \n",
    "            #훈련된 모델을 사용하여 이미지 예측\n",
    "            print(\"hi\")\n",
    "            model=load_model('Building_cnn.h5')\n",
    "            predictions = model.predict(X)  #X이미지 레이블 예측\n",
    "            print(\"bye\")\n",
    "            predictions[0]\n",
    "            result = np.argmax(predictions[0])    # 예측 값중 가장 높은 신뢰도를 가진 레이블\n",
    "\n",
    "            msg = str(categories[result])       # 수신된 메시지 앞에 「echo:」 라는 메시지를 붙힌다.\n",
    "            \n",
    "             #print('New data category : ',categories[result]) #카테고리중 해당되는 것 반환 \n",
    "\n",
    "            #msg = \"se\"\n",
    "            \n",
    "            data = msg.encode() # 바이너리(byte)형식으로 변환한다.\n",
    "       \n",
    "            length = len(data)      # 바이너리의 데이터 사이즈를 구한다.\n",
    "           \n",
    "            client_socket.sendall(length.to_bytes(4, byteorder='big'))  # 데이터 사이즈를 big 엔디언 형식으로 byte로 변환한 다음 전송한다.(※이게 버그인지 big을 써도 little엔디언으로 전송된다.)\n",
    "            \n",
    "            client_socket.sendall(data) # 데이터를 클라이언트로 전송한다. cnn 결과값\n",
    "    except:\n",
    "   \n",
    "        print(\"except : \" , addr)  # 접속이 끊기면 except가 발생한다.\n",
    "    finally:\n",
    "    \n",
    "        client_socket.close() # 접속이 끊기면 socket 리소스를 닫는다.\n",
    "        \n",
    "\n",
    "server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM) # 소켓을 만든다.\n",
    "\n",
    "server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) # 소켓 레벨과 데이터 형태를 설정한다.\n",
    "\n",
    "server_socket.bind(('', 9999)); # 서버는 복수 ip를 사용하는 pc의 경우는 ip를 지정하고 그렇지 않으면 None이 아닌 ''로 설정한다. 포트는 pc내에서 비어있는 포트를 사용한다. cmd에서 netstat -an | find \"LISTEN\"으로 확인할 수 있다.\n",
    "\n",
    "server_socket.listen() # server 설정이 완료되면 listen를 시작한다.\n",
    "try:\n",
    "\n",
    "    while True: # 서버는 여러 클라이언트를 상대하기 때문에 무한 루프를 사용한다.\n",
    "    \n",
    "        client_socket, addr = server_socket.accept() # client로 접속이 발생하면 accept가 발생한다. client 소켓과 addr(주소)를 튜플로 받는다\n",
    "        th = threading.Thread(target=binder, args = (client_socket,addr))  # 쓰레드를 이용해서 client 접속 대기를 만들고 다시 accept로 넘어가서 다른 client를 대기한다.\n",
    "        \n",
    "        th.start()\n",
    "except:\n",
    "    print(\"server\")\n",
    "finally:\n",
    "\n",
    "    server_socket.close() # 에러가 발생하면 서버 소켓을 닫는다.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
