{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os, glob, numpy as np #이미지 프로세싱\n",
    "from sklearn.model_selection import train_test_split #train set과 test set으로 분류 \n",
    "\n",
    "# 데이터셋 저장한 디렉토리\n",
    "base_dir = './KWGuideImg/dataset/train'\n",
    "categories=os.listdir(base_dir) #[\"기념\",\"화도\",\"옥의\",\"비마\",\"새빛\",\"참빛\",\"한울\",\"연구\"]\n",
    "nb_classes=len(categories) #class 개수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#ImageDataGenerator 클래스 사용\n",
    "# 학습 도중에 이미지 변형 가능\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40, #이미지 회전 범위\n",
    "    width_shift_range=0.2, #그림 수평 or 수직으로 랜덤하게 평행이동시키는 범위\n",
    "    height_shift_range=0.2,\n",
    "    rescale=1./255, #1/255로 스케일링하여 0~1버위로 변환하여 효과적으로 학습\n",
    "    shear_range=0.2, #임의 전단 변환\n",
    "    zoom_range=0.2, #임의 확대/축소 범위\n",
    "    horizontal_flip=False, #이미지를 50%확률로 수평으로 뒤집음(뒤집으면 자연스럽지 않으므로, False) \n",
    "    fill_mode='nearest') #이미지를 회전, 이동하거나 축소할 때 생기는 공간 채움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련용 80주념기념관 사진 디렉터리\n",
    "train_ginyeom_dir = './KWGuideImg/dataset/train/gi'\n",
    "\n",
    "# 훈련용 화도관 사진 디렉터리\n",
    "train_hwado_dir = './KWGuideImg/dataset/train/hwan'\n",
    "\n",
    "# 훈련용 새빛관 사진 디렉터리\n",
    "train_saebit_dir = './KWGuideImg/dataset/train/se'\n",
    "\n",
    "# 훈련용 비마관 사진 디렉터리\n",
    "train_bima_dir = './KWGuideImg/dataset/train/bi'\n",
    "\n",
    "# 훈련용 옥의관 사진 디렉터리\n",
    "train_oakui_dir = './KWGuideImg/dataset/train/oak'\n",
    "\n",
    "# 훈련용 한천재 사진 디렉터리\n",
    "train_hancheon_dir = './KWGuideImg/dataset/train/hanchoen'\n",
    "\n",
    "# 훈련용 복지관 사진 디렉터리\n",
    "train_bokji_dir = './KWGuideImg/dataset/train/bok'\n",
    "\n",
    "# 훈련용 연구관 사진 디렉터리\n",
    "train_yeonku_dir = './KWGuideImg/dataset/train/yeon'\n",
    "\n",
    "# 훈련용 참빛관 사진 디렉터리\n",
    "train_chambit_dir = './KWGuideImg/dataset/train/cham'\n",
    "\n",
    "# 훈련용 한울관 사진 디렉터리\n",
    "train_hanoul_dir = './KWGuideImg/dataset/train/hanoul'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 전처리 유틸리티 모듈\n",
    "from keras.preprocessing import image\n",
    "\n",
    "fnames1 = sorted([os.path.join(train_ginyeom_dir, fname) for fname in os.listdir(train_ginyeom_dir)])\n",
    "fnames2 = sorted([os.path.join(train_hwado_dir, fname) for fname in os.listdir(train_hwado_dir)])\n",
    "fnames3 = sorted([os.path.join(train_saebit_dir, fname) for fname in os.listdir(train_saebit_dir)])\n",
    "fnames4 = sorted([os.path.join(train_bima_dir, fname) for fname in os.listdir(train_bima_dir)])\n",
    "fnames5 = sorted([os.path.join(train_oakui_dir, fname) for fname in os.listdir(train_oakui_dir)])\n",
    "fnames6 = sorted([os.path.join(train_chambit_dir, fname) for fname in os.listdir(train_chambit_dir)])\n",
    "fnames7 = sorted([os.path.join(train_hanoul_dir, fname) for fname in os.listdir(train_hanoul_dir)])\n",
    "\n",
    "for img_path in fnames1:\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(150, 150)) # 이미지 읽고 크기 변경\n",
    "\n",
    "    x = image.img_to_array(img) # (150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    x = x.reshape((1,) + x.shape) # (1, 150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    # flow() 메서드로 랜덤하게 변환된 이미지를 배치 단위로 생성하여 폴더에 저장\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,\n",
    "                             save_to_dir='./KWGuideImg/dataset/train/gi',save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > 10:\n",
    "            break #이미지 10장 생성\n",
    "\n",
    "for img_path in fnames2:\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(150, 150)) # 이미지 읽고 크기 변경\n",
    "\n",
    "    x = image.img_to_array(img) # (150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    x = x.reshape((1,) + x.shape) # (1, 150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    # flow() 메서드로 랜덤하게 변환된 이미지를 배치 단위로 생성하여 폴더에 저장\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,\n",
    "                             save_to_dir='./KWGuideImg/dataset/train/hwan',save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > 10:\n",
    "            break #이미지 10장 생성\n",
    "for img_path in fnames3:\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(150, 150)) # 이미지 읽고 크기 변경\n",
    "\n",
    "    x = image.img_to_array(img) # (150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    x = x.reshape((1,) + x.shape) # (1, 150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    # flow() 메서드로 랜덤하게 변환된 이미지를 배치 단위로 생성하여 폴더에 저장\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,\n",
    "                             save_to_dir='./KWGuideImg/dataset/train/se',save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > 10:\n",
    "            break #이미지 10장 생성\n",
    "for img_path in fnames4:\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(150, 150)) # 이미지 읽고 크기 변경\n",
    "\n",
    "    x = image.img_to_array(img) # (150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    x = x.reshape((1,) + x.shape) # (1, 150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    # flow() 메서드로 랜덤하게 변환된 이미지를 배치 단위로 생성하여 폴더에 저장\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,\n",
    "                             save_to_dir='./KWGuideImg/dataset/train/bi',save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > 10:\n",
    "            break #이미지 10장 생성\n",
    "for img_path in fnames5:\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(150, 150)) # 이미지 읽고 크기 변경\n",
    "\n",
    "    x = image.img_to_array(img) # (150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    x = x.reshape((1,) + x.shape) # (1, 150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    # flow() 메서드로 랜덤하게 변환된 이미지를 배치 단위로 생성하여 폴더에 저장\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,\n",
    "                             save_to_dir='./KWGuideImg/dataset/train/oak',save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > 10:\n",
    "            break #이미지 10장 생성\n",
    "for img_path in fnames6:\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(150, 150)) # 이미지 읽고 크기 변경\n",
    "\n",
    "    x = image.img_to_array(img) # (150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    x = x.reshape((1,) + x.shape) # (1, 150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    # flow() 메서드로 랜덤하게 변환된 이미지를 배치 단위로 생성하여 폴더에 저장\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,\n",
    "                             save_to_dir='./KWGuideImg/dataset/train/cham',save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > 10:\n",
    "            break #이미지 10장 생성\n",
    "\n",
    "for img_path in fnames7:\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(150, 150)) # 이미지 읽고 크기 변경\n",
    "\n",
    "    x = image.img_to_array(img) # (150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    x = x.reshape((1,) + x.shape) # (1, 150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    # flow() 메서드로 랜덤하게 변환된 이미지를 배치 단위로 생성하여 폴더에 저장\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,\n",
    "                             save_to_dir='./KWGuideImg/dataset/train/hanoul',save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > 10:\n",
    "            break #이미지 10장 생성            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bi  파일 길이 :  424\n",
      "bi  :  ./KWGuideImg/dataset/train/bi\\image_024.jpg\n",
      "bok  파일 길이 :  7\n",
      "bok  :  ./KWGuideImg/dataset/train/bok\\image_014.jpg\n",
      "cham  파일 길이 :  837\n",
      "cham  :  ./KWGuideImg/dataset/train/cham\\image_029.jpg\n",
      "cham  :  ./KWGuideImg/dataset/train/cham\\_0_8364.jpg\n",
      "gi  파일 길이 :  1937\n",
      "gi  :  ./KWGuideImg/dataset/train/gi\\image_001.jpg\n",
      "gi  :  ./KWGuideImg/dataset/train/gi\\_0_4265.jpg\n",
      "gi  :  ./KWGuideImg/dataset/train/gi\\_0_7438.jpg\n",
      "hanchoen  파일 길이 :  1\n",
      "hanchoen  :  ./KWGuideImg/dataset/train/hanchoen\\image_035.jpg\n",
      "hanoul  파일 길이 :  423\n",
      "hanoul  :  ./KWGuideImg/dataset/train/hanoul\\image_031.jpg\n",
      "hwan  파일 길이 :  1222\n",
      "hwan  :  ./KWGuideImg/dataset/train/hwan\\image_011.jpg\n",
      "hwan  :  ./KWGuideImg/dataset/train/hwan\\_0_6216.jpg\n",
      "oak  파일 길이 :  796\n",
      "oak  :  ./KWGuideImg/dataset/train/oak\\image_025.jpg\n",
      "oak  :  ./KWGuideImg/dataset/train/oak\\_0_884.jpg\n",
      "se  파일 길이 :  836\n",
      "se  :  ./KWGuideImg/dataset/train/se\\image_030.jpg\n",
      "se  :  ./KWGuideImg/dataset/train/se\\_0_8410.jpg\n",
      "yeon  파일 길이 :  3\n",
      "yeon  :  ./KWGuideImg/dataset/train/yeon\\image_032.jpg\n",
      "ok 6486\n"
     ]
    }
   ],
   "source": [
    "image_w = 64\n",
    "image_h = 64 #크기지정\n",
    "\n",
    "pixels = image_h * image_w * 3\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for idx, cat in enumerate(categories):  #각각 카테고리 마다\n",
    "    \n",
    "    label = [0 for i in range(nb_classes)] #0부터 cata 개수만큼\n",
    "    label[idx] = 1\n",
    "\n",
    "    image_ = base_dir + \"/\" + cat\n",
    "    files = glob.glob(image_+\"/*.jpg\")\n",
    "    print(cat, \" 파일 길이 : \", len(files))\n",
    "    for i, f in enumerate(files):\n",
    "        img = Image.open(f)\n",
    "        img = img.convert(\"RGB\")\n",
    "        img = img.resize((image_w, image_h))\n",
    "        data = np.asarray(img)\n",
    "\n",
    "        X.append(data)\n",
    "        y.append(label)\n",
    "\n",
    "        if i % 700 == 0:\n",
    "            print(cat, \" : \", f)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "#1 0 0 0 0 0 0 이면 기념관\n",
    "#0 1 0 0 0 0 0이면 화도관\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "xy = (X_train, X_test, y_train, y_test)\n",
    "np.save('dataset_numpy.npy', xy) #(\"C:/KWGuideImg/dataset/test\", xy) \n",
    "\n",
    "print(\"ok\", len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4864, 64, 64, 3)\n",
      "4864\n"
     ]
    }
   ],
   "source": [
    "#numpy 데이터 불러옴\n",
    "import os, glob, numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend.tensorflow_backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "config =  tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "\n",
    "X_train, X_test, y_train, y_test = np.load('dataset_numpy.npy',allow_pickle=True)\n",
    "print(X_train.shape)\n",
    "print(X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "categories=os.listdir(base_dir)\n",
    "nb_classes = len(categories)\n",
    "\n",
    "#train/ test분류\n",
    "X_train = X_train.astype(float) / 255\n",
    "X_test = X_test.astype(float) / 255\n",
    "print (\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "with K.tf_ops.device('/device:CPU:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:], activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3), padding=\"same\", activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes, activation='sigmoid'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model_dir = './model'\n",
    "    \n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "    \n",
    "    model_path = model_dir + '/multi_img_classification.model'\n",
    "    checkpoint = ModelCheckpoint(filepath=model_path , monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=6)\n",
    "    \n",
    "    print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               4194560   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 4,216,522\n",
      "Trainable params: 4,216,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4864 samples, validate on 1622 samples\n",
      "Epoch 1/30\n",
      "4864/4864 [==============================] - 29s 6ms/step - loss: 1.7610 - accuracy: 0.2794 - val_loss: 1.5329 - val_accuracy: 0.4118\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.53287, saving model to ./model/multi_img_classification.model\n",
      "Epoch 2/30\n",
      "4864/4864 [==============================] - 29s 6ms/step - loss: 1.2571 - accuracy: 0.5181 - val_loss: 0.9584 - val_accuracy: 0.6917\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.53287 to 0.95838, saving model to ./model/multi_img_classification.model\n",
      "Epoch 3/30\n",
      "4864/4864 [==============================] - 30s 6ms/step - loss: 0.7726 - accuracy: 0.7222 - val_loss: 0.5386 - val_accuracy: 0.8397\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.95838 to 0.53856, saving model to ./model/multi_img_classification.model\n",
      "Epoch 4/30\n",
      "4864/4864 [==============================] - 29s 6ms/step - loss: 0.4762 - accuracy: 0.8396 - val_loss: 0.2947 - val_accuracy: 0.9051\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.53856 to 0.29468, saving model to ./model/multi_img_classification.model\n",
      "Epoch 5/30\n",
      "4864/4864 [==============================] - 29s 6ms/step - loss: 0.3353 - accuracy: 0.8943 - val_loss: 0.2206 - val_accuracy: 0.9359\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.29468 to 0.22065, saving model to ./model/multi_img_classification.model\n",
      "Epoch 6/30\n",
      "4864/4864 [==============================] - 29s 6ms/step - loss: 0.2294 - accuracy: 0.9282 - val_loss: 0.1824 - val_accuracy: 0.9445\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.22065 to 0.18239, saving model to ./model/multi_img_classification.model\n",
      "Epoch 7/30\n",
      "4864/4864 [==============================] - 29s 6ms/step - loss: 0.1938 - accuracy: 0.9416 - val_loss: 0.3018 - val_accuracy: 0.9014\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.18239\n",
      "Epoch 8/30\n",
      "4864/4864 [==============================] - 31s 6ms/step - loss: 0.1526 - accuracy: 0.9523 - val_loss: 0.1497 - val_accuracy: 0.9494\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.18239 to 0.14969, saving model to ./model/multi_img_classification.model\n",
      "Epoch 9/30\n",
      "4864/4864 [==============================] - 29s 6ms/step - loss: 0.1252 - accuracy: 0.9624 - val_loss: 0.1297 - val_accuracy: 0.9636\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.14969 to 0.12970, saving model to ./model/multi_img_classification.model\n",
      "Epoch 10/30\n",
      "4864/4864 [==============================] - 32s 7ms/step - loss: 0.1127 - accuracy: 0.9648 - val_loss: 0.1022 - val_accuracy: 0.9698\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.12970 to 0.10221, saving model to ./model/multi_img_classification.model\n",
      "Epoch 11/30\n",
      "4864/4864 [==============================] - 31s 6ms/step - loss: 0.0948 - accuracy: 0.9692 - val_loss: 0.1153 - val_accuracy: 0.9673\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.10221\n",
      "Epoch 12/30\n",
      "4864/4864 [==============================] - 30s 6ms/step - loss: 0.0782 - accuracy: 0.9762 - val_loss: 0.0801 - val_accuracy: 0.9797\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.10221 to 0.08012, saving model to ./model/multi_img_classification.model\n",
      "Epoch 13/30\n",
      "4864/4864 [==============================] - 30s 6ms/step - loss: 0.0646 - accuracy: 0.9784 - val_loss: 0.1054 - val_accuracy: 0.9729\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.08012\n",
      "Epoch 14/30\n",
      "4864/4864 [==============================] - 31s 6ms/step - loss: 0.0611 - accuracy: 0.9817 - val_loss: 0.1199 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.08012\n",
      "Epoch 15/30\n",
      "4864/4864 [==============================] - 28s 6ms/step - loss: 0.0645 - accuracy: 0.9811 - val_loss: 0.1641 - val_accuracy: 0.9451\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.08012\n",
      "Epoch 16/30\n",
      "4864/4864 [==============================] - 30s 6ms/step - loss: 0.0625 - accuracy: 0.9805 - val_loss: 0.0801 - val_accuracy: 0.9809\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.08012 to 0.08010, saving model to ./model/multi_img_classification.model\n",
      "Epoch 17/30\n",
      "4864/4864 [==============================] - 30s 6ms/step - loss: 0.0472 - accuracy: 0.9858 - val_loss: 0.1469 - val_accuracy: 0.9612\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.08010\n",
      "Epoch 18/30\n",
      "4864/4864 [==============================] - 29s 6ms/step - loss: 0.0529 - accuracy: 0.9844 - val_loss: 0.0712 - val_accuracy: 0.9815\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.08010 to 0.07121, saving model to ./model/multi_img_classification.model\n",
      "Epoch 19/30\n",
      "4864/4864 [==============================] - 29s 6ms/step - loss: 0.0541 - accuracy: 0.9813 - val_loss: 0.0895 - val_accuracy: 0.9790\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.07121\n",
      "Epoch 20/30\n",
      "4864/4864 [==============================] - 31s 6ms/step - loss: 0.0389 - accuracy: 0.9868 - val_loss: 0.0913 - val_accuracy: 0.9784\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.07121\n",
      "Epoch 21/30\n",
      "4864/4864 [==============================] - 31s 6ms/step - loss: 0.0453 - accuracy: 0.9827 - val_loss: 0.1007 - val_accuracy: 0.9784\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.07121\n",
      "Epoch 22/30\n",
      "4864/4864 [==============================] - 30s 6ms/step - loss: 0.0638 - accuracy: 0.9788 - val_loss: 0.0983 - val_accuracy: 0.9747\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.07121\n",
      "Epoch 23/30\n",
      "4864/4864 [==============================] - 30s 6ms/step - loss: 0.0305 - accuracy: 0.9905 - val_loss: 0.0885 - val_accuracy: 0.9809\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.07121\n",
      "Epoch 24/30\n",
      "4864/4864 [==============================] - 30s 6ms/step - loss: 0.0249 - accuracy: 0.9912 - val_loss: 0.0912 - val_accuracy: 0.9772\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.07121\n",
      "1622/1622 [==============================] - 2s 1ms/step\n",
      "정확도 : 0.9772\n"
     ]
    }
   ],
   "source": [
    "#validation 변경 -> validation_split=0.2\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=30, validation_data=(X_test, y_test), callbacks=[checkpoint, early_stopping])\n",
    "\n",
    "print(\"정확도 : %.4f\" % (model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_vloss = history.history['val_loss']\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "x_len = np.arange(len(y_loss))\n",
    "\n",
    "plt.plot(x_len, y_vloss, marker='.', c='red', label='val_set_loss')\n",
    "plt.plot(x_len, y_loss, marker='.', c='blue', label='train_set_oss')\n",
    "plt.legend()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img 하나만 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os, glob, numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "test_img='./KWGuideImg/dataset/test/test_img3.jpg'\n",
    "\n",
    "img = Image.open(test_img)\n",
    "img = img.convert(\"RGB\")\n",
    "img = img.resize((image_w, image_h)) #사이즈 재조정\n",
    "data = np.asarray(img)\n",
    "\n",
    "X=np.array(data)\n",
    "\n",
    "X = X.astype(\"float\") / 256\n",
    "X = X.reshape(-1, 64, 64,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data category :  hwan\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X)  \n",
    "result = [np.argmax(value) for value in pred]   # 예측 값중 가장 높은 클래스 반환\n",
    "print('New data category : ',categories[result[0]]) #카테고리중 해당되는 것 반환 => 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os, glob, numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "base_dir = ':C/KWGuideImg/dataset/test' #test img 넣기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "image_w = 64\n",
    "image_h = 64\n",
    "\n",
    "pixels = image_h * image_w * 3\n",
    "\n",
    "X = []\n",
    "filenames = []\n",
    "files = glob.glob(base_dir+\"/*.*\")\n",
    "for i, f in enumerate(files):\n",
    "    img = Image.open(f)\n",
    "    img = img.convert(\"RGB\")\n",
    "    img = img.resize((image_w, image_h))\n",
    "    data = np.asarray(img)\n",
    "    filenames.append(f)  #목록이 예상크기로 조정됨 근듸 왜때문에 input이 안맞는거죠\n",
    "    X.append(data)\n",
    "\n",
    "X = np.array(X)\n",
    "\n",
    "X #왜 아무것도 없을꽈??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./model/multi_img_classification.model')\n",
    "\n",
    "prediction = model.predict(X)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "cnt = 0\n",
    "\n",
    "#prediction = model.predict(test_generator)\n",
    "#np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "\n",
    "for i in prediction:\n",
    "    pre_ans = i.argmax()  # 예측 레이블\n",
    "    print(i)\n",
    "    print(pre_ans)\n",
    "    pre_ans_str = ''\n",
    "    if pre_ans == 0: pre_ans_str = \"기념관\"\n",
    "    elif pre_ans == 1: pre_ans_str = \"화도관\"\n",
    "    elif pre_ans == 2: pre_ans_str = \"옥의관\"\n",
    "    elif pre_ans == 3: pre_ans_str = \"비마관\"\n",
    "    elif pre_ans == 4: pre_ans_str = \"새빛관\"\n",
    "    elif pre_ans == 5: pre_ans_str = \"참빛관\"\n",
    "    elif pre_ans == 6: pre_ans_str =\"한울관\"\n",
    "    elif pre_ans == 7: pre_ans_str =\"복지관\"\n",
    "    elif pre_ans == 8: pre_ans_str =\"한천재\"\n",
    "    else: pre_ans_str = \"연구관\"\n",
    "    \n",
    "    if i[0] >= 0.8 : print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
    "    if i[1] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"으로 추정됩니다.\")\n",
    "    if i[2] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
    "    if i[3] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
    "    if i[4] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
    "    if i[5] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
    "    if i[6] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
    "    if i[7] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
    "    if i[8] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
    "    if i[9] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")    \n",
    "   \n",
    "    cnt += 1\n",
    "    # print(i.argmax()) #얘가 레이블 [1. 0. 0.] 이런식으로 되어 있는 것을 숫자로 바꿔주는 것.\n",
    "    # 즉 얘랑, 나중에 카테고리 데이터 불러와서 카테고리랑 비교를 해서 같으면 맞는거고, 아니면 틀린거로 취급하면 된다.\n",
    "    # 이걸 한 것은 _4.py에."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
