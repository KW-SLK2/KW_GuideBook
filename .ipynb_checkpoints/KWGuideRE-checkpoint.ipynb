{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os, glob, numpy as np #이미지 프로세싱\n",
    "from sklearn.model_selection import train_test_split #train set과 test set으로 분류 \n",
    "\n",
    "# 데이터셋 저장한 디렉토리\n",
    "base_dir = './KWGuideImg/dataset/train'\n",
    "categories=os.listdir(base_dir) #[\"기념\",\"화도\",\"옥의\",\"비마\",\"새빛\",\"참빛\",\"한울\",\"연구\"]\n",
    "nb_classes=len(categories) #class 개수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#ImageDataGenerator 클래스 사용하여 이미지 데이터 증식\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40, #이미지 회전 범위\n",
    "    width_shift_range=0.2, #그림 수평 or 수직으로 랜덤하게 평행이동시키는 범위\n",
    "    height_shift_range=0.2,\n",
    "    rescale=1./255, #1/255로 스케일링하여 0~1범위로 변환하여 효과적으로 학습\n",
    "    shear_range=0.2, #임의 전단 변환\n",
    "    zoom_range=0.2, #임의 확대/축소 범위\n",
    "    horizontal_flip=False, #이미지를 50%확률로 수평으로 뒤집음(뒤집으면 자연스럽지 않으므로, False) \n",
    "    fill_mode='nearest') #이미지를 회전, 이동하거나 축소할 때 생기는 공간 채움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련용 80주념기념관 사진 디렉터리\n",
    "train_ginyeom_dir = './KWGuideImg/dataset/train/gi'\n",
    "\n",
    "# 훈련용 화도관 사진 디렉터리\n",
    "train_hwado_dir = './KWGuideImg/dataset/train/hwan'\n",
    "\n",
    "# 훈련용 새빛관 사진 디렉터리\n",
    "train_saebit_dir = './KWGuideImg/dataset/train/se'\n",
    "\n",
    "# 훈련용 비마관 사진 디렉터리\n",
    "train_bima_dir = './KWGuideImg/dataset/train/bi'\n",
    "\n",
    "# 훈련용 옥의관 사진 디렉터리\n",
    "train_oakui_dir = './KWGuideImg/dataset/train/oak'\n",
    "\n",
    "# 훈련용 한천재 사진 디렉터리\n",
    "train_hancheon_dir = './KWGuideImg/dataset/train/hanchoen'\n",
    "\n",
    "# 훈련용 복지관 사진 디렉터리\n",
    "train_bokji_dir = './KWGuideImg/dataset/train/bok'\n",
    "\n",
    "# 훈련용 연구관 사진 디렉터리\n",
    "train_yeonku_dir = './KWGuideImg/dataset/train/yeon'\n",
    "\n",
    "# 훈련용 참빛관 사진 디렉터리\n",
    "train_chambit_dir = './KWGuideImg/dataset/train/cham'\n",
    "\n",
    "# 훈련용 한울관 사진 디렉터리\n",
    "train_hanoul_dir = './KWGuideImg/dataset/train/hanoul'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 전처리 유틸리티 모듈\n",
    "from keras.preprocessing import image\n",
    "\n",
    "fnames1 = sorted([os.path.join(train_ginyeom_dir, fname) for fname in os.listdir(train_ginyeom_dir)])\n",
    "fnames2 = sorted([os.path.join(train_hwado_dir, fname) for fname in os.listdir(train_hwado_dir)])\n",
    "fnames3 = sorted([os.path.join(train_saebit_dir, fname) for fname in os.listdir(train_saebit_dir)])\n",
    "fnames4 = sorted([os.path.join(train_bima_dir, fname) for fname in os.listdir(train_bima_dir)])\n",
    "fnames5 = sorted([os.path.join(train_oakui_dir, fname) for fname in os.listdir(train_oakui_dir)])\n",
    "fnames6 = sorted([os.path.join(train_chambit_dir, fname) for fname in os.listdir(train_chambit_dir)])\n",
    "fnames7 = sorted([os.path.join(train_hanoul_dir, fname) for fname in os.listdir(train_hanoul_dir)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지 데이터 증식 (한번만 수행)\n",
    "\n",
    "for img_path in fnames1:\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(150, 150)) # 이미지 읽고 크기 변경\n",
    "\n",
    "    x = image.img_to_array(img) # (150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    x = x.reshape((1,) + x.shape) # (1, 150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    # flow() 메서드로 랜덤하게 변환된 이미지를 배치 단위로 생성하여 폴더에 저장\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,\n",
    "                             save_to_dir='./KWGuideImg/dataset/train/gi',save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > 10:\n",
    "            break #이미지 10장 생성\n",
    "\n",
    "for img_path in fnames2:\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(150, 150)) # 이미지 읽고 크기 변경\n",
    "\n",
    "    x = image.img_to_array(img) # (150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    x = x.reshape((1,) + x.shape) # (1, 150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    # flow() 메서드로 랜덤하게 변환된 이미지를 배치 단위로 생성하여 폴더에 저장\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,\n",
    "                             save_to_dir='./KWGuideImg/dataset/train/hwan',save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > 10:\n",
    "            break #이미지 10장 생성\n",
    "for img_path in fnames3:\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(150, 150)) # 이미지 읽고 크기 변경\n",
    "\n",
    "    x = image.img_to_array(img) # (150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    x = x.reshape((1,) + x.shape) # (1, 150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    # flow() 메서드로 랜덤하게 변환된 이미지를 배치 단위로 생성하여 폴더에 저장\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,\n",
    "                             save_to_dir='./KWGuideImg/dataset/train/se',save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > 10:\n",
    "            break #이미지 10장 생성\n",
    "for img_path in fnames4:\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(150, 150)) # 이미지 읽고 크기 변경\n",
    "\n",
    "    x = image.img_to_array(img) # (150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    x = x.reshape((1,) + x.shape) # (1, 150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    # flow() 메서드로 랜덤하게 변환된 이미지를 배치 단위로 생성하여 폴더에 저장\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,\n",
    "                             save_to_dir='./KWGuideImg/dataset/train/bi',save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > 10:\n",
    "            break #이미지 10장 생성\n",
    "for img_path in fnames5:\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(150, 150)) # 이미지 읽고 크기 변경\n",
    "\n",
    "    x = image.img_to_array(img) # (150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    x = x.reshape((1,) + x.shape) # (1, 150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    # flow() 메서드로 랜덤하게 변환된 이미지를 배치 단위로 생성하여 폴더에 저장\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,\n",
    "                             save_to_dir='./KWGuideImg/dataset/train/oak',save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > 10:\n",
    "            break #이미지 10장 생성\n",
    "for img_path in fnames6:\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(150, 150)) # 이미지 읽고 크기 변경\n",
    "\n",
    "    x = image.img_to_array(img) # (150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    x = x.reshape((1,) + x.shape) # (1, 150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    # flow() 메서드로 랜덤하게 변환된 이미지를 배치 단위로 생성하여 폴더에 저장\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,\n",
    "                             save_to_dir='./KWGuideImg/dataset/train/cham',save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > 10:\n",
    "            break #이미지 10장 생성\n",
    "\n",
    "for img_path in fnames7:\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(150, 150)) # 이미지 읽고 크기 변경\n",
    "\n",
    "    x = image.img_to_array(img) # (150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    x = x.reshape((1,) + x.shape) # (1, 150, 150, 3) 크기의 넘파이 배열\n",
    "\n",
    "    # flow() 메서드로 랜덤하게 변환된 이미지를 배치 단위로 생성하여 폴더에 저장\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,\n",
    "                             save_to_dir='./KWGuideImg/dataset/train/hanoul',save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > 10:\n",
    "            break #이미지 10장 생성            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bi  파일 길이 :  424\n",
      "bi  :  ./KWGuideImg/dataset/train/bi\\image_024.jpg\n",
      "bok  파일 길이 :  7\n",
      "bok  :  ./KWGuideImg/dataset/train/bok\\image_014.jpg\n",
      "cham  파일 길이 :  837\n",
      "cham  :  ./KWGuideImg/dataset/train/cham\\image_029.jpg\n",
      "cham  :  ./KWGuideImg/dataset/train/cham\\_0_8364.jpg\n",
      "gi  파일 길이 :  1937\n",
      "gi  :  ./KWGuideImg/dataset/train/gi\\image_001.jpg\n",
      "gi  :  ./KWGuideImg/dataset/train/gi\\_0_4265.jpg\n",
      "gi  :  ./KWGuideImg/dataset/train/gi\\_0_7438.jpg\n",
      "hanchoen  파일 길이 :  1\n",
      "hanchoen  :  ./KWGuideImg/dataset/train/hanchoen\\image_035.jpg\n",
      "hanoul  파일 길이 :  423\n",
      "hanoul  :  ./KWGuideImg/dataset/train/hanoul\\image_031.jpg\n",
      "hwan  파일 길이 :  1222\n",
      "hwan  :  ./KWGuideImg/dataset/train/hwan\\image_011.jpg\n",
      "hwan  :  ./KWGuideImg/dataset/train/hwan\\_0_6216.jpg\n",
      "oak  파일 길이 :  796\n",
      "oak  :  ./KWGuideImg/dataset/train/oak\\image_025.jpg\n",
      "oak  :  ./KWGuideImg/dataset/train/oak\\_0_884.jpg\n",
      "se  파일 길이 :  836\n",
      "se  :  ./KWGuideImg/dataset/train/se\\image_030.jpg\n",
      "se  :  ./KWGuideImg/dataset/train/se\\_0_8410.jpg\n",
      "yeon  파일 길이 :  3\n",
      "yeon  :  ./KWGuideImg/dataset/train/yeon\\image_032.jpg\n",
      "ok 6486\n"
     ]
    }
   ],
   "source": [
    "image_w = 64\n",
    "image_h = 64 #크기지정\n",
    "\n",
    "pixels = image_h * image_w * 3\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for idx, cat in enumerate(categories):  #각 건물마다\n",
    "    \n",
    "    label = [0 for i in range(nb_classes)] #건물 카테고리 개수\n",
    "    label[idx] = 1\n",
    "\n",
    "    image_ = base_dir + \"/\" + cat\n",
    "    files = glob.glob(image_+\"/*.jpg\")\n",
    "    print(cat, \" 파일 길이 : \", len(files))\n",
    "    for i, f in enumerate(files):\n",
    "        img = Image.open(f)\n",
    "        img = img.convert(\"RGB\") #RGB로 변환 \n",
    "        img = img.resize((image_w, image_h)) #크기 (64,64)로 변환\n",
    "        data = np.asarray(img) #numpy.ndarray()형식으로 변환\n",
    "\n",
    "        X.append(data) #train image\n",
    "        y.append(label) #train label \n",
    "\n",
    "        if i % 700 == 0:\n",
    "            print(cat, \" : \", f)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "#1 0 0 0 0 0 0 이면 기념관\n",
    "#0 1 0 0 0 0 0이면 화도관\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y) #트레인이미지와 테스트이미지 나눔\n",
    "xy = (X_train, X_test, y_train, y_test)\n",
    "np.save('dataset_numpy.npy', xy) #(\"C:/KWGuideImg/dataset/test\", xy) \n",
    "\n",
    "print(\"ok\", len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4864, 64, 64, 3)\n",
      "4864\n",
      "(4864, 10)\n"
     ]
    }
   ],
   "source": [
    "#numpy 데이터 불러옴\n",
    "import os, glob, numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend.tensorflow_backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "config =  tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "\n",
    "X_train, X_test, y_train, y_test = np.load('dataset_numpy.npy',allow_pickle=True)\n",
    "print(X_train.shape)\n",
    "print(X_train.shape[0])\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "categories=os.listdir(base_dir)\n",
    "nb_classes = len(categories)\n",
    "\n",
    "#train/ test분류\n",
    "X_train = X_train.astype(float) / 255\n",
    "X_test = X_test.astype(float) / 255\n",
    "print (\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "with K.tf_ops.device('/device:CPU:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:], activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3), padding=\"same\", activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes, activation='sigmoid'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model_dir = './model'\n",
    "    \n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "    \n",
    "    model_path = model_dir + '/multi_img_classification.model'\n",
    "    checkpoint = ModelCheckpoint(filepath=model_path , monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=6)\n",
    "    \n",
    "    print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               4194560   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 4,216,522\n",
      "Trainable params: 4,216,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4864/4864 [==============================] - 30s 6ms/step - loss: 1.7263 - accuracy: 0.3039\n",
      "Epoch 2/10\n",
      "4864/4864 [==============================] - 31s 6ms/step - loss: 1.2802 - accuracy: 0.4801\n",
      "Epoch 3/10\n",
      "4864/4864 [==============================] - 30s 6ms/step - loss: 0.7816 - accuracy: 0.7272\n",
      "Epoch 4/10\n",
      "4864/4864 [==============================] - 30s 6ms/step - loss: 0.5131 - accuracy: 0.8238\n",
      "Epoch 5/10\n",
      "4864/4864 [==============================] - 31s 6ms/step - loss: 0.3386 - accuracy: 0.8914\n",
      "Epoch 6/10\n",
      "4864/4864 [==============================] - 32s 6ms/step - loss: 0.2247 - accuracy: 0.9256\n",
      "Epoch 7/10\n",
      "4864/4864 [==============================] - 31s 6ms/step - loss: 0.1994 - accuracy: 0.9346\n",
      "Epoch 8/10\n",
      "4864/4864 [==============================] - 30s 6ms/step - loss: 0.1558 - accuracy: 0.9496\n",
      "Epoch 9/10\n",
      "4864/4864 [==============================] - 30s 6ms/step - loss: 0.1173 - accuracy: 0.9640\n",
      "Epoch 10/10\n",
      "4864/4864 [==============================] - 30s 6ms/step - loss: 0.1248 - accuracy: 0.9632\n",
      "1622/1622 [==============================] - 2s 1ms/step\n",
      "정확도 : 0.9575\n"
     ]
    }
   ],
   "source": [
    "#validation 변경 -> validation_split=0.2\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=10)\n",
    "#, validation_data=(X_test, y_test), callbacks=[checkpoint, early_stopping]\n",
    "print(\"정확도 : %.4f\" % (model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img 하나만 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os, glob, numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "test_img='./KWGuideImg/dataset/test/test_img3.jpg'\n",
    "img = Image.open(test_img)\n",
    "img.show() #이미지 출력\n",
    "img = img.convert(\"RGB\")\n",
    "img = img.resize((image_w, image_h)) #사이즈 재조정\n",
    "data = np.asarray(img)\n",
    "\n",
    "X=np.array(data)\n",
    "\n",
    "X = X.astype(\"float\") / 256\n",
    "X = X.reshape(-1, 64, 64,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data category :  hwan\n"
     ]
    }
   ],
   "source": [
    "#훈련된 모델을 사용하여 이미지 예측\n",
    "predictions = model.predict(X)  #X이미지 레이블 예측\n",
    "predictions[0]\n",
    "result = np.argmax(predictions[0])    # 예측 값중 가장 높은 신뢰도를 가진 레이블\n",
    "print('New data category : ',categories[result]) #카테고리중 해당되는 것 반환 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img='./KWGuideImg/dataset/test/test_img2.jpg'\n",
    "img = Image.open(test_img)\n",
    "img.show() #이미지 출력\n",
    "img = img.convert(\"RGB\")\n",
    "img = img.resize((image_w, image_h)) #사이즈 재조정\n",
    "data = np.asarray(img)\n",
    "\n",
    "X=np.array(data)\n",
    "\n",
    "X = X.astype(\"float\") / 256\n",
    "X = X.reshape(-1, 64, 64,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data category :  se\n"
     ]
    }
   ],
   "source": [
    "#훈련된 모델을 사용하여 이미지 예측\n",
    "predictions = model.predict(X)  #X이미지 레이블 예측\n",
    "predictions[0]\n",
    "result = np.argmax(predictions[0])    # 예측 값중 가장 높은 신뢰도를 가진 레이블\n",
    "print('New data category : ',categories[result]) #카테고리중 해당되는 것 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
